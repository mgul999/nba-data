# NBA Points Per Game Analysis

Since Jupyter notebooks don't display as nicely in GitHub, click [here](https://nbviewer.jupyter.org/github/mgul999/nba-data/blob/master/PPG.ipynb) to see the PPG notebook rendered properly in nbviewer.

This repository contains two Jupyter notebooks where I analyze NBA statistics. 

* "Generate_Dataset" uses an API to pull data from basketball-reference and assembles it into a CSV containing all per-game statistics since 1980. 
* "PPG" is a series of different models that attempt to predict NBA players' scoring. Out of all the models, a Recurrent Neural Network performed the best, but its performance was still limited by factors outside of its control such as injuries. 

## Overview 
I completed this project after working through Aurelien Geron's *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* as a way to apply my newfound machine learning skills to a topic about which I am very passionate: basketball. To get the data, I used [vishaalagartha's basketball reference scraper](https://github.com/vishaalagartha/basketball_reference_scraper). The data was a bit messier than what I was used to from the book, but I learned a lot from having to clean the data to prepare it for my models. After gathering the data, I established a baseline by assuming that any player will score the same in a season as they did the season before. This baseline "model" had a Mean Squared Error of 12.8 points per game, which all of the other models beat handily. I tried two different approaches: first, I used Linear Regression and Random Forests to try and predict a given seasons' scoring based on various counting statistics from the previous season. These models had a Mean Squared Error of 10.98 and 11.54 respectively, which, although better than the baseline, still left room for improvement. Slightly better was a basic Neural Network, which had an MSE of 10.88. When I added data from the previous two seasons to the model, they improved to 9.44 for Linear Regression, 9.5 for the Random Forest, and 9.7 for the Neural Network. 

The second approach was to use a Recurrent Neural Network to learn the shape of an NBA player's career by training on sets of 6 seasons in order to predict the 7th. This model had a Mean Squared Error of 8.88 on the test set, showing an improvement from the first approach. Ultimately, this prediction was still not as close as I would have liked, but the nature of the NBA limits the performance of a model. There were not as many 7-season stretches for training as I would have wanted, and the seasons with the most erroneous predictions were due to factors out of the model's control. For example, the model predicted that in 2013 Danny Granger would score around 17 PPG, a slight decrease from his 2012 total of 18.7. Given that his scoring had been declining slowly since 2009, this prediction made sense, except for the fact that Danny had a knee injury, and only played 5 games, in which he scored 5.4 points per game. The model was horrendously off here, but it could not have been reasonably expected to predict a knee injury (not yet at least). Many of the worst underperformances can likely be attributed to such precipitous dropoffs; some players also make huge leaps when given more playing time, which the model could not be expected to predict. In conclusion, I'm happy with the way this project turned out, and it was definitely a valuable educational experience to complete a machine learning project on real world data from start to finish. 
